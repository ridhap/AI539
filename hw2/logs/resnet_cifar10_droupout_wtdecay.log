Model: resnet
Dataset: cifar10
Learning Rate: 0.01
No.of Epochs: 50
Weight Decay: 0.0005
DropOut
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Train:- Loss: 0.782 | Acc: 42.902% (21451/50000)
Test:-  Loss: 1.384 | Acc: 52.380% (5238/10000)
Saving..

Epoch: 1
Train:- Loss: 0.525 | Acc: 62.850% (31425/50000)
Test:-  Loss: 0.931 | Acc: 67.730% (6773/10000)
Saving..

Epoch: 2
Train:- Loss: 0.402 | Acc: 72.038% (36019/50000)
Test:-  Loss: 0.775 | Acc: 73.490% (7349/10000)
Saving..

Epoch: 3
Train:- Loss: 0.332 | Acc: 77.022% (38511/50000)
Test:-  Loss: 0.675 | Acc: 77.200% (7720/10000)
Saving..

Epoch: 4
Train:- Loss: 0.282 | Acc: 80.518% (40259/50000)
Test:-  Loss: 0.599 | Acc: 80.050% (8005/10000)
Saving..

Epoch: 5
Train:- Loss: 0.251 | Acc: 82.982% (41491/50000)
Test:-  Loss: 0.565 | Acc: 81.530% (8153/10000)
Saving..

Epoch: 6
Train:- Loss: 0.225 | Acc: 84.576% (42288/50000)
Test:-  Loss: 0.552 | Acc: 81.610% (8161/10000)
Saving..

Epoch: 7
Train:- Loss: 0.200 | Acc: 86.172% (43086/50000)
Test:-  Loss: 0.538 | Acc: 82.380% (8238/10000)
Saving..

Epoch: 8
Train:- Loss: 0.182 | Acc: 87.506% (43753/50000)
Test:-  Loss: 0.524 | Acc: 83.090% (8309/10000)
Saving..

Epoch: 9
Train:- Loss: 0.166 | Acc: 88.574% (44287/50000)
Test:-  Loss: 0.461 | Acc: 84.510% (8451/10000)
Saving..

Epoch: 10
Train:- Loss: 0.150 | Acc: 89.634% (44817/50000)
Test:-  Loss: 0.501 | Acc: 83.350% (8335/10000)

Epoch: 11
Train:- Loss: 0.139 | Acc: 90.464% (45232/50000)
Test:-  Loss: 0.440 | Acc: 85.440% (8544/10000)
Saving..

Epoch: 12
Train:- Loss: 0.126 | Acc: 91.240% (45620/50000)
Test:-  Loss: 0.557 | Acc: 81.940% (8194/10000)

Epoch: 13
Train:- Loss: 0.116 | Acc: 91.890% (45945/50000)
Test:-  Loss: 0.512 | Acc: 83.720% (8372/10000)

Epoch: 14
Train:- Loss: 0.113 | Acc: 92.146% (46073/50000)
Test:-  Loss: 0.492 | Acc: 84.980% (8498/10000)

Epoch: 15
Train:- Loss: 0.096 | Acc: 93.290% (46645/50000)
Test:-  Loss: 0.438 | Acc: 86.190% (8619/10000)
Saving..

Epoch: 16
Train:- Loss: 0.089 | Acc: 93.796% (46898/50000)
Test:-  Loss: 0.436 | Acc: 86.320% (8632/10000)
Saving..

Epoch: 17
Train:- Loss: 0.087 | Acc: 93.834% (46917/50000)
Test:-  Loss: 0.466 | Acc: 85.880% (8588/10000)

Epoch: 18
Train:- Loss: 0.080 | Acc: 94.392% (47196/50000)
Test:-  Loss: 0.466 | Acc: 86.310% (8631/10000)

Epoch: 19
Train:- Loss: 0.070 | Acc: 95.114% (47557/50000)
Test:-  Loss: 0.417 | Acc: 87.380% (8738/10000)
Saving..

Epoch: 20
Train:- Loss: 0.066 | Acc: 95.358% (47679/50000)
Test:-  Loss: 0.459 | Acc: 86.760% (8676/10000)

Epoch: 21
Train:- Loss: 0.064 | Acc: 95.458% (47729/50000)
Test:-  Loss: 0.423 | Acc: 87.220% (8722/10000)

Epoch: 22
Train:- Loss: 0.057 | Acc: 96.080% (48040/50000)
Test:-  Loss: 0.429 | Acc: 87.700% (8770/10000)
Saving..

Epoch: 23
Train:- Loss: 0.053 | Acc: 96.262% (48131/50000)
Test:-  Loss: 0.459 | Acc: 86.680% (8668/10000)

Epoch: 24
Train:- Loss: 0.054 | Acc: 96.260% (48130/50000)
Test:-  Loss: 0.416 | Acc: 87.950% (8795/10000)
Saving..

Epoch: 25
Train:- Loss: 0.045 | Acc: 97.008% (48504/50000)
Test:-  Loss: 0.433 | Acc: 87.660% (8766/10000)

Epoch: 26
Train:- Loss: 0.048 | Acc: 96.722% (48361/50000)
Test:-  Loss: 0.425 | Acc: 87.960% (8796/10000)
Saving..

Epoch: 27
Train:- Loss: 0.043 | Acc: 97.054% (48527/50000)
Test:-  Loss: 0.472 | Acc: 86.940% (8694/10000)

Epoch: 28
Train:- Loss: 0.043 | Acc: 97.126% (48563/50000)
Test:-  Loss: 0.419 | Acc: 88.230% (8823/10000)
Saving..

Epoch: 29
Train:- Loss: 0.038 | Acc: 97.404% (48702/50000)
Test:-  Loss: 0.431 | Acc: 88.150% (8815/10000)

Epoch: 30
Train:- Loss: 0.034 | Acc: 97.694% (48847/50000)
Test:-  Loss: 0.468 | Acc: 87.740% (8774/10000)

Epoch: 31
Train:- Loss: 0.033 | Acc: 97.774% (48887/50000)
Test:-  Loss: 0.459 | Acc: 87.970% (8797/10000)

Epoch: 32
Train:- Loss: 0.035 | Acc: 97.592% (48796/50000)
Test:-  Loss: 0.429 | Acc: 88.500% (8850/10000)
Saving..

Epoch: 33
Train:- Loss: 0.033 | Acc: 97.758% (48879/50000)
Test:-  Loss: 0.457 | Acc: 87.760% (8776/10000)

Epoch: 34
Train:- Loss: 0.032 | Acc: 97.810% (48905/50000)
Test:-  Loss: 0.422 | Acc: 88.140% (8814/10000)

Epoch: 35
Train:- Loss: 0.028 | Acc: 98.168% (49084/50000)
Test:-  Loss: 0.437 | Acc: 88.210% (8821/10000)

Epoch: 36
Train:- Loss: 0.026 | Acc: 98.246% (49123/50000)
Test:-  Loss: 0.433 | Acc: 88.610% (8861/10000)
Saving..

Epoch: 37
Train:- Loss: 0.026 | Acc: 98.272% (49136/50000)
Test:-  Loss: 0.426 | Acc: 88.900% (8890/10000)
Saving..

Epoch: 38
Train:- Loss: 0.023 | Acc: 98.496% (49248/50000)
Test:-  Loss: 0.452 | Acc: 88.170% (8817/10000)

Epoch: 39
Train:- Loss: 0.025 | Acc: 98.324% (49162/50000)
Test:-  Loss: 0.462 | Acc: 87.940% (8794/10000)

Epoch: 40
Train:- Loss: 0.022 | Acc: 98.526% (49263/50000)
Test:-  Loss: 0.495 | Acc: 88.040% (8804/10000)

Epoch: 41
Train:- Loss: 0.024 | Acc: 98.352% (49176/50000)
Test:-  Loss: 0.421 | Acc: 88.980% (8898/10000)
Saving..

Epoch: 42
Train:- Loss: 0.023 | Acc: 98.572% (49286/50000)
Test:-  Loss: 0.439 | Acc: 88.500% (8850/10000)

Epoch: 43
Train:- Loss: 0.022 | Acc: 98.540% (49270/50000)
Test:-  Loss: 0.446 | Acc: 88.570% (8857/10000)

Epoch: 44
Train:- Loss: 0.021 | Acc: 98.602% (49301/50000)
Test:-  Loss: 0.413 | Acc: 89.210% (8921/10000)
Saving..

Epoch: 45
Train:- Loss: 0.018 | Acc: 98.834% (49417/50000)
Test:-  Loss: 0.436 | Acc: 89.160% (8916/10000)

Epoch: 46
Train:- Loss: 0.019 | Acc: 98.736% (49368/50000)
Test:-  Loss: 0.476 | Acc: 88.250% (8825/10000)

Epoch: 47
Train:- Loss: 0.018 | Acc: 98.878% (49439/50000)
Test:-  Loss: 0.420 | Acc: 89.180% (8918/10000)

Epoch: 48
Train:- Loss: 0.021 | Acc: 98.662% (49331/50000)
Test:-  Loss: 0.444 | Acc: 88.250% (8825/10000)

Epoch: 49
Train:- Loss: 0.020 | Acc: 98.756% (49378/50000)
Test:-  Loss: 0.444 | Acc: 88.540% (8854/10000)
Completed
[0.7823801401173672, 0.5245048877070931, 0.4016100830015014, 0.3324246617686718, 0.28233002507320754, 0.2505492603077608, 0.225273561513866, 0.20043438749240183, 0.18163524954901328, 0.16578068478447397, 0.1498589922085671, 0.13877719807941133, 0.12561095243467546, 0.11575776300228693, 0.11313166064412697, 0.095606042448517, 0.08947733190396558, 0.08674096178901775, 0.07976820486862107, 0.07033440622660662, 0.06643580262789793, 0.06370024005834804, 0.05704538126254592, 0.05266126265804119, 0.053720371089065855, 0.044526592507074726, 0.04755329437460989, 0.043338359007254586, 0.04252148834872953, 0.038288203445310844, 0.033727061354776704, 0.032597767149843755, 0.03475494455674763, 0.03320136517726952, 0.032437634214287255, 0.027509826145407593, 0.025958554232534726, 0.026044504696746237, 0.023111524475861074, 0.0250706145098633, 0.02229387692028128, 0.024396851606940363, 0.022525498157163457, 0.022464867093382388, 0.02112338380055035, 0.018194873999033714, 0.019124664939910798, 0.01775976339028493, 0.021010491789033983, 0.019904656890470683] [1.3844341396526167, 0.930585000545356, 0.7750861980732838, 0.6753290519592868, 0.5989339938209315, 0.5648394130217801, 0.5515779632671624, 0.5378411296446612, 0.5239484473398537, 0.46053980233942626, 0.5007299260254119, 0.4404049838424488, 0.5567779729890215, 0.5120254804374306, 0.4915180181621746, 0.43809002666336716, 0.43645886146718527, 0.4663894666702884, 0.4656812566670643, 0.41718206464484997, 0.45928068511235487, 0.42340508758262463, 0.42908764127523275, 0.45936757440020326, 0.4164454196194175, 0.43321819166848613, 0.4246188716334143, 0.47187387516164475, 0.41905788583740305, 0.43090766288672283, 0.46817044405990343, 0.45895547538426273, 0.4289810467202952, 0.4571164677477187, 0.42176478574420234, 0.4370389853123647, 0.4325694930591401, 0.42629654344859397, 0.4522224418866407, 0.4620672043911211, 0.4951668027669761, 0.42146028032538235, 0.4386275978225052, 0.4461926665560455, 0.4126591136216358, 0.4358010037689452, 0.47587263655320855, 0.41970552686767976, 0.4436458864124717, 0.4441937223361556] [42.902, 62.85, 72.038, 77.022, 80.518, 82.982, 84.576, 86.172, 87.506, 88.574, 89.634, 90.464, 91.24, 91.89, 92.146, 93.29, 93.796, 93.834, 94.392, 95.114, 95.358, 95.458, 96.08, 96.262, 96.26, 97.008, 96.722, 97.054, 97.126, 97.404, 97.694, 97.774, 97.592, 97.758, 97.81, 98.168, 98.246, 98.272, 98.496, 98.324, 98.526, 98.352, 98.572, 98.54, 98.602, 98.834, 98.736, 98.878, 98.662, 98.756] [52.38, 67.73, 73.49, 77.2, 80.05, 81.53, 81.61, 82.38, 83.09, 84.51, 83.35, 85.44, 81.94, 83.72, 84.98, 86.19, 86.32, 85.88, 86.31, 87.38, 86.76, 87.22, 87.7, 86.68, 87.95, 87.66, 87.96, 86.94, 88.23, 88.15, 87.74, 87.97, 88.5, 87.76, 88.14, 88.21, 88.61, 88.9, 88.17, 87.94, 88.04, 88.98, 88.5, 88.57, 89.21, 89.16, 88.25, 89.18, 88.25, 88.54]
