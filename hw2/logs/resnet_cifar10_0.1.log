========================================================================================================================
Model: resnet
Dataset: cifar10
Learning Rate: 0.01
No.of Epochs: 50
Weight Decay: 0.1
DropOut
========================================================================================================================
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
========================================================================================================================
==> Building model..

Epoch: 0
Train:- Loss: 1.120 | Acc: 16.816% (8408/50000)
Test:-  Loss: 2.251 | Acc: 10.960% (1096/10000)
Saving..

Epoch: 1
Train:- Loss: 1.069 | Acc: 17.430% (8715/50000)
Test:-  Loss: 2.402 | Acc: 9.810% (981/10000)

Epoch: 2
Train:- Loss: 1.059 | Acc: 17.254% (8627/50000)
Test:-  Loss: 2.448 | Acc: 9.990% (999/10000)

Epoch: 3
Train:- Loss: 1.062 | Acc: 17.226% (8613/50000)
Test:-  Loss: 2.351 | Acc: 10.200% (1020/10000)

Epoch: 4
Train:- Loss: 1.058 | Acc: 17.540% (8770/50000)
Test:-  Loss: 2.469 | Acc: 10.050% (1005/10000)

Epoch: 5
Train:- Loss: 1.056 | Acc: 17.446% (8723/50000)
Test:-  Loss: 2.414 | Acc: 10.080% (1008/10000)

Epoch: 6
Train:- Loss: 1.059 | Acc: 17.646% (8823/50000)
Test:-  Loss: 2.362 | Acc: 10.080% (1008/10000)

Epoch: 7
Train:- Loss: 1.065 | Acc: 17.496% (8748/50000)
Test:-  Loss: 2.372 | Acc: 10.130% (1013/10000)

Epoch: 8
Train:- Loss: 1.069 | Acc: 16.996% (8498/50000)
Test:-  Loss: 2.253 | Acc: 14.720% (1472/10000)
Saving..

Epoch: 9
Train:- Loss: 1.071 | Acc: 17.426% (8713/50000)
Test:-  Loss: 2.258 | Acc: 11.690% (1169/10000)

Epoch: 10
Train:- Loss: 1.075 | Acc: 17.248% (8624/50000)
Test:-  Loss: 2.230 | Acc: 16.060% (1606/10000)
Saving..

Epoch: 11
Train:- Loss: 1.076 | Acc: 17.212% (8606/50000)
Test:-  Loss: 2.187 | Acc: 16.970% (1697/10000)
Saving..

Epoch: 12
Train:- Loss: 1.078 | Acc: 17.260% (8630/50000)
Test:-  Loss: 2.253 | Acc: 12.630% (1263/10000)

Epoch: 13
Train:- Loss: 1.077 | Acc: 17.222% (8611/50000)
Test:-  Loss: 6.228 | Acc: 9.960% (996/10000)

Epoch: 14
Train:- Loss: 1.079 | Acc: 17.140% (8570/50000)
Test:-  Loss: 2.323 | Acc: 10.110% (1011/10000)

Epoch: 15
Train:- Loss: 1.080 | Acc: 17.114% (8557/50000)
Test:-  Loss: 2.196 | Acc: 16.150% (1615/10000)

Epoch: 16
Train:- Loss: 1.074 | Acc: 17.042% (8521/50000)
Test:-  Loss: 2.256 | Acc: 12.260% (1226/10000)

Epoch: 17
Train:- Loss: 1.076 | Acc: 16.974% (8487/50000)
Test:-  Loss: 3.298 | Acc: 9.900% (990/10000)

Epoch: 18
Train:- Loss: 1.140 | Acc: 10.900% (5450/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 19
Train:- Loss: 1.151 | Acc: 10.056% (5028/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 20
Train:- Loss: 1.151 | Acc: 9.920% (4960/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 21
Train:- Loss: 1.151 | Acc: 10.062% (5031/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 22
Train:- Loss: 1.151 | Acc: 10.042% (5021/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 23
Train:- Loss: 1.151 | Acc: 9.908% (4954/50000)
Test:-  Loss: 2.304 | Acc: 9.990% (999/10000)

Epoch: 24
Train:- Loss: 1.152 | Acc: 9.662% (4831/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 25
Train:- Loss: 1.152 | Acc: 9.930% (4965/50000)
Test:-  Loss: 2.303 | Acc: 10.170% (1017/10000)

Epoch: 26
Train:- Loss: 1.151 | Acc: 10.110% (5055/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 27
Train:- Loss: 1.152 | Acc: 9.918% (4959/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 28
Train:- Loss: 1.151 | Acc: 10.052% (5026/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 29
Train:- Loss: 1.151 | Acc: 9.680% (4840/50000)
Test:-  Loss: 2.303 | Acc: 9.980% (998/10000)

Epoch: 30
Train:- Loss: 1.151 | Acc: 9.922% (4961/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 31
Train:- Loss: 1.152 | Acc: 9.682% (4841/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 32
Train:- Loss: 1.151 | Acc: 9.730% (4865/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 33
Train:- Loss: 1.151 | Acc: 9.960% (4980/50000)
Test:-  Loss: 2.303 | Acc: 9.630% (963/10000)

Epoch: 34
Train:- Loss: 1.151 | Acc: 9.804% (4902/50000)
Test:-  Loss: 2.303 | Acc: 9.970% (997/10000)

Epoch: 35
Train:- Loss: 1.152 | Acc: 9.812% (4906/50000)
Test:-  Loss: 2.303 | Acc: 9.990% (999/10000)

Epoch: 36
Train:- Loss: 1.151 | Acc: 9.948% (4974/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 37
Train:- Loss: 1.152 | Acc: 10.078% (5039/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 38
Train:- Loss: 1.151 | Acc: 9.824% (4912/50000)
Test:-  Loss: 2.303 | Acc: 9.990% (999/10000)

Epoch: 39
Train:- Loss: 1.151 | Acc: 9.932% (4966/50000)
Test:-  Loss: 2.303 | Acc: 9.990% (999/10000)

Epoch: 40
Train:- Loss: 1.151 | Acc: 10.012% (5006/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 41
Train:- Loss: 1.151 | Acc: 10.086% (5043/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 42
Train:- Loss: 1.151 | Acc: 9.758% (4879/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 43
Train:- Loss: 1.151 | Acc: 9.760% (4880/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 44
Train:- Loss: 1.151 | Acc: 9.988% (4994/50000)
Test:-  Loss: 2.303 | Acc: 9.910% (991/10000)

Epoch: 45
Train:- Loss: 1.151 | Acc: 9.894% (4947/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 46
Train:- Loss: 1.152 | Acc: 9.962% (4981/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 47
Train:- Loss: 1.152 | Acc: 9.900% (4950/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 48
Train:- Loss: 1.151 | Acc: 9.910% (4955/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)

Epoch: 49
Train:- Loss: 1.151 | Acc: 9.926% (4963/50000)
Test:-  Loss: 2.303 | Acc: 10.000% (1000/10000)
========================================================================================================================
[1.1200014207216784, 1.0687942018594279, 1.058743162990531, 1.0617447978700214, 1.0582050997430406, 1.0563385224403323, 1.059424448348677, 1.064569766716579, 1.0687790538953699, 1.071021868597211, 1.0750355696129372, 1.076361957108578, 1.0778108739182162, 1.0770961209331327, 1.07902454933547, 1.0800296113923993, 1.0744407695272695, 1.0761668128735573, 1.1399623559563972, 1.1514807773368132, 1.1514435285497504, 1.1514900645331654, 1.1514760118616207, 1.1514458622773895, 1.1515279134825978, 1.1515270750540907, 1.1514910142440016, 1.1515101563290258, 1.151408715931046, 1.1514927757060742, 1.1514946115596214, 1.151513361717429, 1.1514744682385183, 1.1514284763189837, 1.151452143631323, 1.1515328460337255, 1.1514621380040102, 1.1515258414970944, 1.1514311458753503, 1.151498937850718, 1.1514787934625241, 1.151381927835362, 1.1514957862741806, 1.151451289348895, 1.1514344912050936, 1.1514332169462043, 1.1515022790645395, 1.1515038685725474, 1.1514780297303748, 1.151422938422474] [2.251476989430227, 2.401537064534084, 2.4479552211275526, 2.351191563211429, 2.469199127452389, 2.4142968517959496, 2.3619699204803273, 2.371977405183634, 2.2528038617152317, 2.2584388225701204, 2.229590753081498, 2.1865866336093585, 2.2531112288213837, 6.228456111470605, 2.3233556033699374, 2.1960571176686865, 2.256299188941907, 3.297640332750454, 2.302796772331189, 2.302809738049841, 2.30297584746294, 2.3028836204747485, 2.3027277828022172, 2.3035408281216956, 2.302931023251479, 2.3028652910973615, 2.3029878822861205, 2.3028605333559073, 2.3030494459115776, 2.3028490740782135, 2.3031334998501336, 2.30314597658291, 2.302965121664059, 2.302834018780168, 2.302971273470836, 2.3026554113740376, 2.302777691251913, 2.302995078882594, 2.3029290855310527, 2.3028039567789453, 2.3027938384159357, 2.3028863888637274, 2.3027372405787183, 2.3027331662026183, 2.302648264891023, 2.3027758567955843, 2.302687412614276, 2.302738071247271, 2.3027883760488717, 2.3031081348467786] [16.816, 17.43, 17.254, 17.226, 17.54, 17.446, 17.646, 17.496, 16.996, 17.426, 17.248, 17.212, 17.26, 17.222, 17.14, 17.114, 17.042, 16.974, 10.9, 10.056, 9.92, 10.062, 10.042, 9.908, 9.662, 9.93, 10.11, 9.918, 10.052, 9.68, 9.922, 9.682, 9.73, 9.96, 9.804, 9.812, 9.948, 10.078, 9.824, 9.932, 10.012, 10.086, 9.758, 9.76, 9.988, 9.894, 9.962, 9.9, 9.91, 9.926] [10.96, 9.81, 9.99, 10.2, 10.05, 10.08, 10.08, 10.13, 14.72, 11.69, 16.06, 16.97, 12.63, 9.96, 10.11, 16.15, 12.26, 9.9, 10.0, 10.0, 10.0, 10.0, 10.0, 9.99, 10.0, 10.17, 10.0, 10.0, 10.0, 9.98, 10.0, 10.0, 10.0, 9.63, 9.97, 9.99, 10.0, 10.0, 9.99, 9.99, 10.0, 10.0, 10.0, 10.0, 9.91, 10.0, 10.0, 10.0, 10.0, 10.0]
